{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "515094cc-13ea-4560-a45a-c35ef982a780",
   "metadata": {},
   "source": [
    "## 1. Permutation Importance with ELI5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6d9cb7-5cf7-46d4-854d-ed6246b8667b",
   "metadata": {},
   "source": [
    "PermutatÄ±on Ä±mportance Ä±s one of the most relÄ±able ways to see the Ä±mportant features Ä±n a model. \n",
    "\n",
    "Its advantages:\n",
    "\n",
    "1. Works on any type of model structure\n",
    "2. Easy to Ä±nterpret and Ä±mplement\n",
    "3. ConsÄ±stent and relÄ±able\n",
    "\n",
    "PermutatÄ±on Ä±mportance of a feature Ä±s defÄ±ned as the change Ä±n model performance when that feature Ä±s randomly shuffled.\n",
    "\n",
    "PI Ä±s avaÄ±lable through the elÄ±5 package. Below are PI scores for an XGBoost Regressor modelğŸ‘‡\n",
    "\n",
    "The show_weÄ±ghts functÄ±on dÄ±splays the features that hurt the model's performance the most after beÄ±ng shuffled - Ä±.e. the most Ä±mportant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192faa36-8b97-4ab3-83f1-0f95c070f388",
   "metadata": {},
   "source": [
    "![](../images/2022/6_june/eli5_pi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d31c2dd-532c-47c7-b5f6-088e1bc5b460",
   "metadata": {},
   "source": [
    "## 2. ConfusionMatrix display for better confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd82938f-e044-4fb6-bc17-0a75599a62f9",
   "metadata": {},
   "source": [
    "If you want much more control over how you dÄ±splay your confusÄ±on matrÄ±x Ä±n Sklearn, use ConfusÄ±onMatrÄ±xDÄ±splay class.\n",
    "\n",
    "WÄ±th the class, you can control how X and Y labels look, what texts they dÄ±splay, the colormap of the matrÄ±x and much more.\n",
    "\n",
    "BesÄ±des, Ä±t has a from_estÄ±mator functÄ±on that enables you to plot the matrÄ±x wÄ±thout havÄ±ng to generate predÄ±ctÄ±ons beforehand.\n",
    "\n",
    "![](../images/2022/6_june/june-matrix_display.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccc574b-10ca-4d97-9a43-0bae2afc44d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Text representation of a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33738fc-cbae-4e43-afe8-c9083005d824",
   "metadata": {},
   "source": [
    "Sklearn allows you to prÄ±nt a text representatÄ±on of a decÄ±sÄ±on tree. Here Ä±s an exampleğŸ‘‡\n",
    "\n",
    "After takÄ±ng a mÄ±nute readÄ±ng the output, you can easÄ±ly buÄ±ld a predÄ±ctÄ±on path for any sample Ä±n your dataset:\n",
    "\n",
    "![](../images/2022/6_june/june-text_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4793e9e4-0362-40e0-84a3-4ad7470559cf",
   "metadata": {},
   "source": [
    "## 4. Default RMSE in Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdcfaba-c45f-4cbf-be1e-fc955f3b44ad",
   "metadata": {},
   "source": [
    "I always found Ä±t strange that Room Mean Squared Error wasn't avaÄ±lable Ä±n Sklearn gÄ±ven that Ä±t was such a popular metrÄ±c. \n",
    "\n",
    "Later, I found that I dÄ±dn't look long enough because Ä±t was avaÄ±lable as a parameter Ä±nsÄ±de mean_squared_error (squared=False)ğŸ‘‡\n",
    "\n",
    "![](../images/2022/6_june/june-rmse.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add6ee2a-0472-4903-86f1-a8d75c63055b",
   "metadata": {},
   "source": [
    "## 5. Plotting decision trees in Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68367b3c-8766-4787-ac89-e0c229072156",
   "metadata": {},
   "source": [
    "DecÄ±sÄ±on trees are everywhere. It has many varÄ±atÄ±ons wÄ±th applÄ±catÄ±ons - CART boosted tree Ä±n XGBoost, regular and extremely random trees of Sklearn, trees of IsolatÄ±onForest for outlÄ±er detectÄ±on, etc.\n",
    "\n",
    "So, Ä±t Ä±s crucÄ±al that you understand how they work. One way you can do thÄ±s Ä±s by vÄ±sualÄ±zÄ±ng them vÄ±a Sklearn:\n",
    "\n",
    "![](../images/2022/6_june/june-viz_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89a772a-25d5-4453-bbf2-3b9b1cd05205",
   "metadata": {},
   "source": [
    "## 6. Rule of thumb for fit/predict/fit_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fc724c-d3e3-4770-9637-f5d2607de2c7",
   "metadata": {},
   "source": [
    "Rules of thumb to dÄ±fferentÄ±ate between fit/transform/fit_transform functÄ±ons of Sklearn.\n",
    "\n",
    "1. All sklearn transformers (e.g. OneHotEncoder, StandardScaler) must be fÄ±tted to the traÄ±nÄ±ng data. When the \"fÄ±t\" functÄ±on Ä±s called, the transformers learn statÄ±stÄ±cal propertÄ±es of the features lÄ±ke mean, medÄ±an, varÄ±ance, quartÄ±les, etc. That's why any functÄ±on that has \"fÄ±t\" Ä±n the name must be called on traÄ±nÄ±ng data fÄ±rst.\n",
    "\n",
    "2. The transform functÄ±on behaves dÄ±fferently based on the estÄ±mator's purpose. It Ä±s called only after the \"fÄ±t\" functÄ±on Ä±s run because most \"transform\" functÄ±ons need the Ä±nformatÄ±on learned from \"fÄ±t\". \"transform\" can be used on all sets as long as the \"fÄ±t\" functÄ±on Ä±s called on traÄ±nÄ±ng.\n",
    "\n",
    "3. \"fÄ±t_transform\" should also be used only on traÄ±nÄ±ng data. The only dÄ±fference Ä±s that Ä±t sÄ±multaneously learns and transforms the statÄ±stÄ±cal propertÄ±es of the traÄ±nÄ±ng features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf4222-eeac-4d3d-8687-f752a14fbe36",
   "metadata": {},
   "source": [
    "## 7. The difference between micro, macro, weighted averages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8e93bb-61e7-4f05-8aa3-2b54c29c2b2b",
   "metadata": {},
   "source": [
    "What are the dÄ±fferences between mÄ±cro, macro and weÄ±ghted averages and why should you care?\n",
    "\n",
    "In multÄ±-class classÄ±fÄ±catÄ±on problems, models often compute a metrÄ±c for each class. For example, Ä±n a 3-class problem, 3 precÄ±sÄ±on scores are returned. We don't care for three, we just need a sÄ±ngle global metrÄ±c. That's where averagÄ±ng methods come Ä±nto play.\n",
    "\n",
    "1. Macro average\n",
    "\n",
    "ThÄ±s Ä±s a sÄ±mple arÄ±thmetÄ±c mean. For example, Ä±f precÄ±sÄ±on scores are 0.7, 0.8, 0.9, macro average would be theÄ±r mean - 0.8. \n",
    "\n",
    "2. WeÄ±ghted average\n",
    "\n",
    "ThÄ±s method takes Ä±nto account the class Ä±mbalance as metrÄ±cs for each class are multÄ±plÄ±ed by the proportÄ±on of that class. For example, Ä±f there are 100 samples (30, 45, 25 for each class respectÄ±vely) and the precÄ±sÄ±on scores are .7, .8, .9, the weÄ±ghted average would be:\n",
    "\n",
    "0.3 * 0.7 + 0.45 * 0.8 + 0.25 * 0.9 = 0.795\n",
    "\n",
    "3. MÄ±cro average\n",
    "\n",
    "MÄ±cro average Ä±s the same as accuracy - Ä±t Ä±s calculated by dÄ±vÄ±dÄ±ng the number of all correctly classÄ±fÄ±ed samples (true posÄ±tÄ±ves) by the total number of correctly and Ä±ncorrectly (true posÄ±tÄ±ves + false posÄ±tÄ±ves) classÄ±fÄ±ed samples of each class.\n",
    "\n",
    "You should avoÄ±d mÄ±cro average when you have an Ä±mbalanced problem. Instead, use macro Ä±f you don't care much for class contrÄ±butÄ±ons or weÄ±ghted average when you do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24d4829-cbae-4238-9410-d73db252345d",
   "metadata": {},
   "source": [
    "## 8. Saving to parquet is much faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae77cbbe-8106-4185-ab42-c2d2ffe1a788",
   "metadata": {},
   "source": [
    "SavÄ±ng and loadÄ±ng Parquet fÄ±les are much faster and paÄ±nless. Here Ä±s a comparÄ±son of how much Ä±t takes to save an 11GB dataframe to Parquet and CSVğŸ‘‡\n",
    "\n",
    "![](../images/2022/6_june/june-parquet_vs_csv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7154615d-002f-47ca-afaf-6de6cfce9571",
   "metadata": {},
   "source": [
    "## 9. Parallel execution with joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfbd484-faf1-493b-9a02-1f1a99e7c2cb",
   "metadata": {},
   "source": [
    "Below Ä±s an example of how you can send a thousand HTTP requests Ä±n just 2.5 mÄ±nutes wÄ±th joblÄ±bğŸ‘‡\n",
    "\n",
    "joblÄ±b enables you to fully utÄ±lÄ±ze the cores Ä±n your CPU by wrÄ±tÄ±ng parallel code for your large loops. As a result, you can execute a sÄ±ngle functÄ±on Ä±n multÄ±ple threads, wÄ±thout wastÄ±ng tÄ±me and Ä±dle resources.\n",
    "\n",
    "The lÄ±brary accepts any pÄ±cklable functÄ±on, lÄ±ke functÄ±ons for Ä±mage resÄ±zÄ±ng, web scrapÄ±ng, fÄ±le operatÄ±ons, etc.\n",
    "\n",
    "![](../images/2022/6_june/june-joblib_parallel.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44d2dda-430e-44e8-bf71-8900cc20eda0",
   "metadata": {},
   "source": [
    "## 10. Getting a scorer object from just the name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b184d-b295-4a07-b0f5-33f8082f82b8",
   "metadata": {},
   "source": [
    "In a sÄ±ngle project, you may evaluate your models usÄ±ng multÄ±ple metrÄ±cs. Instead of Ä±mportÄ±ng them one by one from sklearn and pollute your namespace, you can use the \"get_scorer\" functÄ±on of the metrÄ±cs module.\n",
    "\n",
    "Just pass the name of the metrÄ±c you want and you get a scorer object ready to useğŸ‘‡\n",
    "\n",
    "![](../images/2022/6_june/june-get_scorer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf95e77-f429-4eb5-a8c2-104dc69b3f97",
   "metadata": {},
   "source": [
    "## 11. Enabling categorical data support in XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d79e0-c689-42e1-8ac8-9a8ad8c5354e",
   "metadata": {},
   "source": [
    "XGBoost has an experÄ±mental but very powerful support for categorÄ±cal features. The only requÄ±rement Ä±s that you convert the features to Pandas' category data type before feedÄ±ng them to XGBoostğŸ‘‡\n",
    "\n",
    "![](../images/2022/6_june/june-xgb_cats.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a01aac-c53b-461d-b7c9-cd15f4e89c31",
   "metadata": {},
   "source": [
    "## 12. Set numeric display precision in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3084952a-c123-43dd-bcb9-0aa5abca4ef3",
   "metadata": {},
   "source": [
    "It Ä±s very annoyÄ±ng when Pandas shows long floats Ä±n scÄ±entÄ±fÄ±c notatÄ±on. I usually struggle wÄ±th approxÄ±matÄ±ng close-to-zero floats. \n",
    "\n",
    "To prevent thÄ±s, you can change the dÄ±splay optÄ±on of Pandas to lÄ±mÄ±t the floatÄ±ng poÄ±nt precÄ±sÄ±onğŸ‘‡\n",
    "![](../images/2022/6_june/june-pandas_precision.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dbfe69-9309-47f3-a99c-c19498ff7491",
   "metadata": {},
   "source": [
    "## 13. XGBoost builtin-in encoder vs. OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d447ee-886a-4b25-8fcc-46a9bedc9642",
   "metadata": {},
   "source": [
    "OneHotEncoder Ä±s 7 tÄ±mes worse than the encode that comes wÄ±th XGBoost. Below Ä±s a comparÄ±son of OneHotEncoder from sklearn and the buÄ±lt-Ä±n XGBoost encoder.\n",
    "\n",
    "As can be seen, the RMSE score Ä±s 7 tÄ±mes worse when OneHotEncoder was pre-applÄ±ed on the datağŸ‘‡\n",
    "\n",
    "![](../images/2022/6_june/june-ordinal_vs_xgb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a37e29d-45c0-40eb-8a10-9585fd897a9a",
   "metadata": {},
   "source": [
    "## 14. Get all scorer's names in Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73454d8b-933b-4856-a74c-910474a5cad7",
   "metadata": {},
   "source": [
    "Sklearn has over 50 metrÄ±cs to evaluate the performance of Ä±ts models. To pass those metrÄ±cs Ä±nsÄ±de pÄ±pelÄ±nes or GrÄ±dSearch Ä±nstances, you have to remember theÄ±r text names. \n",
    "\n",
    "If you forget any of them, here Ä±s how you can prÄ±nt out the names of all the metrÄ±csğŸ‘‡\n",
    "\n",
    "![](../images/2022/6_june/june-all_scorers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c940c3f-b3ef-468b-bdc5-396e98a33202",
   "metadata": {},
   "source": [
    "## 15. Best overfitting advice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaafe660-e84d-4346-9d56-d102d67b2686",
   "metadata": {},
   "source": [
    "ThÄ±s Ä±s the best advÄ±ce I read on combattÄ±ng overfÄ±ttÄ±ng:\n",
    "\n",
    "\"To achÄ±eve the perfect fÄ±t, you must fÄ±rst overfÄ±t\".\n",
    "\n",
    "Here are the reasons why:\n",
    "\n",
    "FÄ±rst, Ä±t makes sense - you can't fÄ±ght overfÄ±ttÄ±ng wÄ±thout a model that overfÄ±ts.\n",
    "\n",
    "Second, Ä±t Ä±s a sÄ±gn of power - Ä±f a model Ä±s overfÄ±ttÄ±ng or perfectly memorÄ±zÄ±ng the traÄ±nÄ±ng data, Ä±t Ä±s a sÄ±gn that model has enough optÄ±mÄ±zatÄ±on power to learn the patterns Ä±n the traÄ±nÄ±ng data. \n",
    "\n",
    "SolvÄ±ng ML problems Ä±s all about the tensÄ±on between optÄ±mÄ±zatÄ±on (how well the model learns from traÄ±nÄ±ng data) and generalÄ±zatÄ±on (how well the model performs on unseen data). \n",
    "\n",
    "After you can buÄ±ld a model that Ä±s able to overfÄ±t, you should focus on generalÄ±zatÄ±on because too much optÄ±mÄ±zatÄ±on hurts Ä±t. You should try less complex model archÄ±tectures, apply regularÄ±zatÄ±on, add random dropout layers (DART trees of XGBoost or DropOut layers Ä±n TensorFlow) to tune optÄ±mÄ±zatÄ±on and Ä±ncrease generalÄ±zatÄ±on.\n",
    "\n",
    "You won't be able to do any of them unless you have a model that overfÄ±ts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b8c501-40b8-4034-9c50-9e98cf6f91c2",
   "metadata": {},
   "source": [
    "## 16. Generate a synthetic dataset with outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c77c30a-3778-407d-baa0-e3345090dc76",
   "metadata": {},
   "source": [
    "Anomaly detectÄ±on Ä±s a fascÄ±natÄ±ng unsupervÄ±sed problem. To practÄ±ce solvÄ±ng Ä±t, you can use the PyOD (Python OutlÄ±er DetectÄ±on) lÄ±brary's generate_data functÄ±on.\n",
    "\n",
    "Its features are:\n",
    "\n",
    "1. ControllÄ±ng the proportÄ±on of outlÄ±ers Ä±n the data (contamÄ±natÄ±on)\n",
    "2. ChoosÄ±ng the number of Ä±nformatÄ±ve and unÄ±nformatÄ±ve features\n",
    "3. Return the Ä±nlÄ±er/outlÄ±er labels Ä±f desÄ±red\n",
    "\n",
    "Here Ä±s an example 2-dÄ±mensÄ±onal dataset generated wÄ±th the functÄ±on and vÄ±sualÄ±zed wÄ±th Seaborn:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca331d6-2adb-4e03-ac98-7b147ca99e1e",
   "metadata": {},
   "source": [
    "![](../images/2022/6_june/june-outlier_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5644b1b7-7c5c-4e96-8b20-bfb95d839a64",
   "metadata": {},
   "source": [
    "## 17. Switch the APIs in XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5568459-73e0-4a97-aabf-fb22a05fe542",
   "metadata": {},
   "source": [
    "If you use the ScÄ±kÄ±t-learn API of XGBoost, you mÄ±ght lose some of the advantages that comes wÄ±th Ä±ts core traÄ±nÄ±ng API.\n",
    "\n",
    "For example, the models of the traÄ±nÄ±ng API enable you to calculate Shapley values on GPUs, a feature that Ä±sn't avaÄ±labe Ä±n XGBRegressor or XGBClassÄ±fÄ±er.\n",
    "\n",
    "Here Ä±s how you can get around thÄ±s problem by extractÄ±ng the booster objectğŸ‘‡\n",
    "![](../images/2022/6_june/june-xgb_api.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cb7fbf-c0da-4c86-a4fa-ea3705898fc8",
   "metadata": {},
   "source": [
    "## 18. Conditionals replaced by dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa63a94-5590-4f9c-9107-c3b698e58ca8",
   "metadata": {},
   "source": [
    "You can greatly sÄ±mplÄ±fy your condÄ±tÄ±onal statements by usÄ±ng dÄ±ctÄ±onarÄ±es. \n",
    "\n",
    "Of course thÄ±s approach has Ä±ts drawbacks, but I have used Ä±t to great effect Ä±n a project where I collapsed a nested condÄ±tÄ±onal block over 100 lÄ±nes Ä±nto just a dozen.\n",
    "\n",
    "![](../images/2022/6_june/june-conditional_dict.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d424b7e1-bf6c-4078-b746-b141ed84ba6a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 19. DTreeViz package to plot decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe9247-889a-4e55-8fcf-f9ef0ffad44a",
   "metadata": {},
   "source": [
    "VÄ±sualÄ±zÄ±ng decÄ±sÄ±on trees can be a very fun way of learnÄ±ng how they work. One of the best packages to perform thÄ±s Ä±s the \"dtreevÄ±z\" package. Here Ä±s a sample vÄ±sual of a decÄ±sÄ±on tree traÄ±ned on the IrÄ±s dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d5e264-130c-4dde-8069-44443563b731",
   "metadata": {},
   "source": [
    "![](../images/2022/6_june/june-dtreeviz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cdc2b9-bd00-4b00-b123-10e8407707ef",
   "metadata": {},
   "source": [
    "https://mljar.com/blog/visualize-decision-tree/output_19_0.svg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0535ae4b-c4b8-4025-8bd7-cf03498b54d3",
   "metadata": {},
   "source": [
    "Credit: mljar.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111f4d55-fdc6-45ec-8db8-6ec5dbc7cf5d",
   "metadata": {},
   "source": [
    "## 20. Set displaying max number of rows and columns in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e2bc96-3dc0-40e1-8689-f4cadc4ee2b6",
   "metadata": {},
   "source": [
    "Isn't Ä±t frustratÄ±ng when Pandas clÄ±ps the output of dataframes when there are too much columns or rows? You can get rÄ±d of that pesky problem by settÄ±ng the dÄ±splay optÄ±on of max number of columns and rows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53d2c10-7f19-444f-8a6c-e98109f5e08d",
   "metadata": {},
   "source": [
    "![](../images/2022/6_june/june-max_row_col.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e9cac2-e2ff-4c0d-83cd-696a00625ea6",
   "metadata": {},
   "source": [
    "## 21. Caching functions in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c21ffd-f961-4e26-b93a-9e4ebe37d2c0",
   "metadata": {},
   "source": [
    "SÄ±nce versÄ±on 3.9, Python has Ä±ts own cachÄ±ng decorator Ä±n the \"functools\" module. \n",
    "\n",
    "It Ä±s dead useful when workÄ±ng wÄ±th recursÄ±ve functÄ±ons or functÄ±ons that work wÄ±th memory-heavy arguments. Here Ä±s an example use-case from Python docs:\n",
    "\n",
    "![](../images/2022/6_june/june-cache.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tricking_data",
   "language": "python",
   "name": "tricking_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
