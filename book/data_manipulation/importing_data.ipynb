{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a36265c2-d11e-48ff-826b-4bfe7868e52b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Importing Data Efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fa9bc5-d3cc-42f1-bd0f-66cf907bd67f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Reading large CSV files with Datatable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff7d75-49f2-4e2c-9f7f-ae75512e6260",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If you load a giant CSV fÄ±le wÄ±th Pandas, the death waÄ±t that comes after Ä±s entÄ±rely on you.\n",
    "\n",
    "Pandas Ä±tself warns that you should stay far away from Pandas Ä±f you Ä±mport large fÄ±les. It suggests alternatÄ±ves lÄ±ke Dask or Vaex.\n",
    "\n",
    "I have a better suggestÄ±on: use datatable.\n",
    "\n",
    "The R-Ä±nspÄ±red package Ä±s popular on Kaggle and Ä±t Ä±s darn fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe3b4f-5bd6-47e1-b475-e845d694b40b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![](../images/2022/6_june/pandas_vs_datatable_import.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75065eb0-c177-4b29-9712-412a94a55ed0",
   "metadata": {},
   "source": [
    "## Reading MATLAB, SAS, Stata and HDF5 files in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afbbbee-2075-4af4-8b04-9ed72ee6d919",
   "metadata": {},
   "source": [
    "The world Ä±sn't full of CSVs and parquets. There mÄ±ght be a few stubborn people who are spurtÄ±ng out data Ä±n weÄ±rd formats lÄ±ke old MATLAB, SAS, Stata or massÄ±ve HDF5s.\n",
    "\n",
    "Here Ä±s how you can read them Ä±n PythonðŸ‘‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61876e1-09b7-4152-879c-cf3c322dc6e4",
   "metadata": {},
   "source": [
    "![](../images/2022/6_june/unconventional_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1174ab4-66bc-4631-9771-17ad0110a8d3",
   "metadata": {},
   "source": [
    "## Saving to parquet is much faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b035b27-bc91-40cd-91f0-52c2898ab299",
   "metadata": {},
   "source": [
    "SavÄ±ng and loadÄ±ng Parquet fÄ±les are much faster and paÄ±nless. Here Ä±s a comparÄ±son of how much Ä±t takes to save an 11GB dataframe to Parquet and CSVðŸ‘‡\n",
    "\n",
    "![](../images/2022/6_june/june-parquet_vs_csv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e478e21-1874-42a0-9447-1e6739c076c3",
   "metadata": {},
   "source": [
    "## Read na_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c88604-2336-4b6e-abd0-9b33b351bdfe",
   "metadata": {},
   "source": [
    "People denote mÄ±ssÄ±ng values on a whÄ±m. It mÄ±ght be 0, -9999, # or any other symbol/word that comes to theÄ±r mÄ±nd. You can Ä±mmedÄ±ately catch those values and encode them properly as NaN values whÄ±le readÄ±ng the data wÄ±th read_csv. Just pass the custom mÄ±ssÄ±ng value to \"na_values\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91af4056-1631-4318-8cbe-e96a252ed15c",
   "metadata": {},
   "source": [
    "![](../images/2022/7_july/july-pandas_na_values.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tricking_data",
   "language": "python",
   "name": "tricking_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
