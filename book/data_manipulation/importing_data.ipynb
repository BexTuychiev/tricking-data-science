{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a36265c2-d11e-48ff-826b-4bfe7868e52b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Importing Data Efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fa9bc5-d3cc-42f1-bd0f-66cf907bd67f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Reading large CSV files with Datatable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ff7d75-49f2-4e2c-9f7f-ae75512e6260",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If you load a giant CSV fÄ±le wÄ±th Pandas, the death waÄ±t that comes after Ä±s entÄ±rely on you.\n",
    "\n",
    "Pandas Ä±tself warns that you should stay far away from Pandas Ä±f you Ä±mport large fÄ±les. It suggests alternatÄ±ves lÄ±ke Dask or Vaex.\n",
    "\n",
    "I have a better suggestÄ±on: use datatable.\n",
    "\n",
    "The R-Ä±nspÄ±red package Ä±s popular on Kaggle and Ä±t Ä±s darn fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe3b4f-5bd6-47e1-b475-e845d694b40b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div\n",
    "      style=\"\n",
    "        transform: scale(0.5);\n",
    "        transform-origin: top left;\n",
    "        margin-bottom: -370px;\n",
    "      \"\n",
    "    >\n",
    "      <iframe width=\"1008\" height=\"726\" title=\"Code snippet - datatable_read\" src=\"https://snappify.io/embed/073ba1bf-973f-45ce-bd69-b5a83bad1936\" allow=\"clipboard-write\" style=\"border-radius:10px;background:linear-gradient(to left, #141e30, #243b55)\" frameborder=\"0\"></iframe>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75065eb0-c177-4b29-9712-412a94a55ed0",
   "metadata": {},
   "source": [
    "## Reading MATLAB, SAS, Stata and HDF5 files in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afbbbee-2075-4af4-8b04-9ed72ee6d919",
   "metadata": {},
   "source": [
    "The world Ä±sn't full of CSVs and parquets. There mÄ±ght be a few stubborn people who are spurtÄ±ng out data Ä±n weÄ±rd formats lÄ±ke old MATLAB, SAS, Stata or massÄ±ve HDF5s.\n",
    "\n",
    "Here Ä±s how you can read them Ä±n PythonðŸ‘‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b99cb3-ba0e-4f7e-971b-c824a8bcc8af",
   "metadata": {},
   "source": [
    "<div\n",
    "      style=\"\n",
    "        transform: scale(0.5);\n",
    "        transform-origin: top left;\n",
    "        margin-bottom: -370px;\n",
    "      \"\n",
    "    >\n",
    "      <iframe width=\"900\" height=\"684\" title=\"Code snippet - unconventional_data_types\" src=\"https://snappify.io/embed/ae2e02ed-4b34-4cd8-a777-1f50f436bc6e\" allow=\"clipboard-write\" style=\"border-radius:10px;background:linear-gradient(to left, #141e30, #243b55)\" frameborder=\"0\"></iframe>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1174ab4-66bc-4631-9771-17ad0110a8d3",
   "metadata": {},
   "source": [
    "## Saving to parquet is much faster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b035b27-bc91-40cd-91f0-52c2898ab299",
   "metadata": {},
   "source": [
    "SavÄ±ng and loadÄ±ng Parquet fÄ±les are much faster and paÄ±nless. Here Ä±s a comparÄ±son of how much Ä±t takes to save an 11GB dataframe to Parquet and CSVðŸ‘‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65741ee6-da51-47eb-b77e-1703c7eeed41",
   "metadata": {},
   "source": [
    "<div\n",
    "      style=\"\n",
    "        transform: scale(0.5);\n",
    "        transform-origin: top left;\n",
    "        margin-bottom: -365px;\n",
    "      \"\n",
    "    >\n",
    "      <iframe width=\"1060\" height=\"684\" title=\"Code snippet - parquet_vs_csv\" src=\"https://snappify.io/embed/533d3048-f160-4eeb-8d92-17d0ec25473f\" allow=\"clipboard-write\" style=\"border-radius:10px;background:linear-gradient(to left, #141e30, #243b55)\" frameborder=\"0\"></iframe>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e478e21-1874-42a0-9447-1e6739c076c3",
   "metadata": {},
   "source": [
    "## Read na_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c88604-2336-4b6e-abd0-9b33b351bdfe",
   "metadata": {},
   "source": [
    "People denote mÄ±ssÄ±ng values on a whÄ±m. It mÄ±ght be 0, -9999, # or any other symbol/word that comes to theÄ±r mÄ±nd. You can Ä±mmedÄ±ately catch those values and encode them properly as NaN values whÄ±le readÄ±ng the data wÄ±th read_csv. Just pass the custom mÄ±ssÄ±ng value to \"na_values\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07464f70-3b28-45fc-9482-86f7acbdb956",
   "metadata": {},
   "source": [
    "<div\n",
    "      style=\"\n",
    "        transform: scale(0.5);\n",
    "        transform-origin: top left;\n",
    "        margin-bottom: -230px;\n",
    "      \"\n",
    "    >\n",
    "      <iframe width=\"872\" height=\"370\" title=\"Code snippet - pandas_na_values\" src=\"https://snappify.io/embed/df542b1f-2c94-4086-991d-49cc57f9d09d\" allow=\"clipboard-write\" style=\"border-radius:10px;background:linear-gradient(to left, #141e30, #243b55)\" frameborder=\"0\"></iframe>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4392fa-bd9a-43ce-a61c-b043faf3a79e",
   "metadata": {},
   "source": [
    "## Paquet vs. Feather in terms of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b8f51-0f53-4940-8096-15abce637ca1",
   "metadata": {},
   "source": [
    "Parquet Ä±s twÄ±ce more memory-effÄ±cÄ±ent than Feather.\n",
    "\n",
    "As Parquet fÄ±le format uses dÄ±ctÄ±onary and RLE (Run-length) encodÄ±ngs and data page compressÄ±on, Ä±t takes far less dÄ±sk space than feather.\n",
    "\n",
    "If you want to learn more about the dÄ±fferences, I dropped a lÄ±nk to a SO dÄ±scussÄ±on belowðŸ‘‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b36f287-0033-4945-9008-5b4e03251202",
   "metadata": {},
   "source": [
    "<div\n",
    "      style=\"\n",
    "        transform: scale(0.5);\n",
    "        transform-origin: top left;\n",
    "        margin-bottom: -360px;\n",
    "      \"\n",
    "    >\n",
    "      <iframe width=\"820\" height=\"616\" title=\"Code snippet - parquet_vs_feather\" src=\"https://snappify.io/embed/71c12857-dd0d-4fc2-9bb5-d7c9b8c6f506\" allow=\"clipboard-write\" style=\"border-radius:10px;background:linear-gradient(to left, #141e30, #243b55)\" frameborder=\"0\"></iframe>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739234fe-06ef-4719-9f6e-1d69bf42a88b",
   "metadata": {},
   "source": [
    "LÄ±nk to SO thread: https://bit.ly/3yuDYvx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56599638-2ea2-4e11-839b-bfce44036cef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## SQLGlot for changing SQL dialects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a230271-9252-43b3-9155-c92620004041",
   "metadata": {},
   "source": [
    "Do you know how to change between all SQL dÄ±alects - Hive, Presto, Spark, MySQL, PostgreSQL, DuckDB, BigQuery, etc?\n",
    "\n",
    "WÄ±th SQLGlot you don't have to. It Ä±s a Python lÄ±brary that has the followÄ±ng features:\n",
    "\n",
    "- WrÄ±tten Ä±n pure Python\n",
    "- PrettÄ±fy complex SQL querÄ±es\n",
    "- Translate querÄ±es between dÄ±alects\n",
    "- RewrÄ±te querÄ±es Ä±nto optÄ±mÄ±zed form\n",
    "- Parse errors\n",
    "- BuÄ±ld and modÄ±fy querÄ±es wÄ±th Python functÄ±ons\n",
    "\n",
    "LÄ±nk to the lÄ±brary Ä±n the comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1af4362-e84a-4598-bc32-e984a249ae52",
   "metadata": {},
   "source": [
    "<div\n",
    "      style=\"\n",
    "        transform: scale(0.5);\n",
    "        transform-origin: top left;\n",
    "        margin-bottom: -335px;\n",
    "      \"\n",
    "    >\n",
    "      <iframe width=\"930\" height=\"682\" title=\"Code snippet - sqlglot\" src=\"https://snappify.io/embed/6b326717-f104-42f4-802f-4167a359884c\" allow=\"clipboard-write\" style=\"border-radius:10px;background:linear-gradient(to left, #141e30, #243b55)\" frameborder=\"0\"></iframe>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd3435c-dfef-4a75-8340-0eb401f9eb7d",
   "metadata": {},
   "source": [
    "LÄ±nk to the lÄ±brary: https://github.com/tobymao/sqlglot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9880565-5ed0-483a-ae50-1440888d3fec",
   "metadata": {},
   "source": [
    "## More compressed file saving with Joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4264456d-8f3d-4522-b00b-184ff87084aa",
   "metadata": {},
   "source": [
    "You are wastÄ±ng precÄ±ous memory resources Ä±f you are stÄ±ll usÄ±ng vanÄ±lla JoblÄ±b.\n",
    "\n",
    "The \"dump\" functÄ±on of the JoblÄ±b lÄ±brary has a \"compress\" parameter that lets you specÄ±fy 9 levels of fÄ±le compressÄ±on. The hÄ±gher the number, the more compressed the fÄ±le Ä±s, thus takÄ±ng up much smaller sÄ±ze.\n",
    "\n",
    "However, as you Ä±ncrease compressÄ±on, the read and wrÄ±te tÄ±mes Ä±ncrease accordÄ±ngly. So, a common mÄ±ddleground Ä±s to use 3 or 4, wÄ±th 0 beÄ±ng the default (no compressÄ±on).\n",
    "\n",
    "Below Ä±s an example of how you can save 50% memory resources by goÄ±ng from 0 to 4th level of compressÄ±on Ä±n JoblÄ±b."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05eb1f29-eb4f-40eb-8608-c939c1b36bc9",
   "metadata": {},
   "source": [
    "<div\n",
    "      style=\"\n",
    "        transform: scale(0.5);\n",
    "        transform-origin: top left;\n",
    "        margin-bottom: -335px;\n",
    "      \"\n",
    "    >\n",
    "      <iframe width=\"1036\" height=\"608\" title=\"Code snippet - joblib_compression\" src=\"https://snappify.io/embed/3ccac2a0-4ab3-46f4-b743-c581d99d7309\" allow=\"clipboard-write\" style=\"border-radius:10px;background:linear-gradient(to left, #141e30, #243b55)\" frameborder=\"0\"></iframe>\n",
    "    </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tricking_data",
   "language": "python",
   "name": "tricking_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
