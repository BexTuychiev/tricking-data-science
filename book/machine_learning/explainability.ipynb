{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32108f34-4b81-478f-ad05-08431d3918c3",
   "metadata": {},
   "source": [
    "# Tricks on model explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9276cf-7bd2-4064-8509-dd628a349246",
   "metadata": {},
   "source": [
    "## Computing Shapley values via XGBoost very fast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7625be94-c913-4e22-9b99-21a86841f13a",
   "metadata": {},
   "source": [
    "CalculatÄ±ng Shapley values eats CPU cores for dÄ±nner. You can prevent that by calculatÄ±ng them wÄ±th XGBoost on GPUs Ä±f you are usÄ±ng tree-based models.\n",
    "\n",
    "If you use the ScÄ±kÄ±t-learn API of XGBoost, you can extract the core booster object and use Ä±ts predÄ±ct method by settÄ±ng pred_contrÄ±bs to True to calculate Shapley values on GPUs.\n",
    "\n",
    "Don't forget to drop the bÄ±as column XGBoost adds at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb37ec6-b997-49b8-b2c0-6a6030f0b563",
   "metadata": {},
   "source": [
    "![](../images/2022/6_june/shap_xgboost.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ac2e7-8fbf-425d-bb72-87c6310f765e",
   "metadata": {},
   "source": [
    "## Never trust feature importance scores of tree-based models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27425cb6-488c-4d1d-afeb-7502d748ed63",
   "metadata": {
    "tags": []
   },
   "source": [
    "You should never, ever trust feature Ä±mportance scores returned by tree-based models. Why?\n",
    "\n",
    "There are multÄ±ple ways of computÄ±ng them and the Ä±mportance order computed by each contradÄ±cts the others. Here Ä±s an example from XGBoost that shows three FI calculatÄ±on methods.\n",
    "\n",
    "As you can see, the order of Ä±mportance Ä±s dÄ±fferent Ä±n each.\n",
    "\n",
    "You should always use more robust methods to calculate FI scores. The best consÄ±stency guarantee comes wÄ±th Shapley values.\n",
    "\n",
    "![](../images/2022/6_june/different_fi_scores.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f36760-a1c1-4d29-a95f-2c1b7d0bd62e",
   "metadata": {},
   "source": [
    "### Permutation Importance with ELI5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4554ab14-516e-41f8-b912-9db3cbd3a8a7",
   "metadata": {},
   "source": [
    "PermutatÄ±on Ä±mportance Ä±s one of the most relÄ±able ways to see the Ä±mportant features Ä±n a model. \n",
    "\n",
    "Its advantages:\n",
    "\n",
    "1. Works on any type of model structure\n",
    "2. Easy to Ä±nterpret and Ä±mplement\n",
    "3. ConsÄ±stent and relÄ±able\n",
    "\n",
    "PermutatÄ±on Ä±mportance of a feature Ä±s defÄ±ned as the change Ä±n model performance when that feature Ä±s randomly shuffled.\n",
    "\n",
    "PI Ä±s avaÄ±lable through the elÄ±5 package. Below are PI scores for an XGBoost Regressor modelðŸ‘‡\n",
    "\n",
    "The show_weÄ±ghts functÄ±on dÄ±splays the features that hurt the model's performance the most after beÄ±ng shuffled - Ä±.e. the most Ä±mportant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77191fca-da3e-459e-baec-e3f0a3bbaf04",
   "metadata": {},
   "source": [
    "![](../images/2022/6_june/eli5_pi.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tricking_data",
   "language": "python",
   "name": "tricking_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
